# -*- coding: utf-8 -*-
"""gradio_visualization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jGgCxB6aOCDSGrfd7r33GNSWFwbnXtN5
"""

import os, time
import matplotlib.pyplot as plt
import itertools
import pickle
import imageio
import torch
from PIL import Image
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import torchvision.utils as vutils
import numpy as np
from torch.utils.data import DataLoader
from torchvision.transforms import Compose

Z_DIM = 100
Y_DIM = NUM_CLASS = 4

MAP = torch.diag(torch.ones(4))
device = torch.device("cpu")

def normal_init(m, mean, std):
  if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
    m.weight.data.normal_(mean, std)
    m.bias.data.zero_()

class generator(nn.Module):
  # Paper Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S

        # self.deconv1_1 = nn.ConvTranspose2d(100, 128*2, 4, 1, 0)
        # self.deconv1_1_bn = nn.BatchNorm2d(d*2)
        # self.deconv1_2 = nn.ConvTranspose2d(10, d*2, 4, 1, 0)
        # self.deconv1_2_bn = nn.BatchNorm2d(d*2)
        # self.deconv2 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)
        # self.deconv2_bn = nn.BatchNorm2d(d*2)
        # self.deconv3 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)
        # self.deconv3_bn = nn.BatchNorm2d(d)
        # self.deconv4 = nn.ConvTranspose2d(d, 1, 4, 2, 1)

  def __init__(self):
    super(generator,self).__init__()
    self.h1 = nn.Sequential(
    nn.Linear(in_features=Z_DIM+Y_DIM, out_features=256 * 4 * 4),
    nn.LeakyReLU(negative_slope=0.2),)
    
    # upsample n*n -> 2n * 2n
    self.up1 = nn.Sequential(
        nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),
        # 128 is the channel size, should match with the real image data loader,H = (H1 - 1)*stride + HF - 2*padding
        nn.LeakyReLU(negative_slope=0.2)
    )
    self.up2 = nn.Sequential(
        nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=4, stride=2, padding=1),
        nn.LeakyReLU(negative_slope=0.2)
    )
    self.output = nn.Sequential(
        nn.Conv2d(in_channels=128, out_channels=3, kernel_size=3, padding=1),  # 3 means the RGB channel
        nn.Tanh()
    )

  def forward(self, x,label):
    x = torch.cat([x,label],1).to(device)
    # print("x after concatenate: ",x.shape) # [64, 112]
    out = self.h1(x)
    # print("shape after the first hidden layer: ",out.shape) #[64, 4096]
    # print("shape after the first hidden layer: ",out.shape)
    out = out.view(-1, 256, 4, 4)
    out = self.up1(out)
    out = self.up2(out)
    out = self.up2(out)  # [64, 128, 32, 32]
    # print("shape after up2: ",out.shape)
    out = self.output(out)
    return out

  # weight_init
  def weight_init(self, mean, std):
    for m in self._modules:
        normal_init(self._modules[m], mean, std)

class discriminator(nn.Module):
  # Paper Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S

  def __init__(self):
    super(discriminator, self).__init__()
    # input size: [batch_size, channel, height, width ] [64,3,32,32]
    self.batch_size = 64
    self.conv = nn.Sequential(
        # normal [64,32,32] padding=1 to keep shape the same
        nn.Conv2d(in_channels=3+1, out_channels=64, kernel_size=3, padding=1),
        nn.LeakyReLU(negative_slope=0.2),

        # down sampling [128,32,32]
        # nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=17),
        # nn.LeakyReLU(negative_slope=0.2),

        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
        nn.LeakyReLU(negative_slope=0.2),

        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),
        nn.LeakyReLU(negative_slope=0.2),
        #
        # nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=17),#[256,32,32]
        # nn.LeakyReLU(negative_slope=0.2),
        # classifier
        nn.Flatten(),
        nn.Dropout(p=0.4)
    )
    self.fc = nn.Sequential(
        nn.Linear(in_features=256 * 32 * 32, out_features=1),
        nn.Sigmoid()  # may be not proper to use sigmoid for binary classification problem?
    )

    # following layer is for processing label:
    self.process_label = nn.Sequential(
        nn.Linear(in_features = NUM_CLASS,out_features=1*32*32),
        nn.LeakyReLU(negative_slope=0.2)
    )

  def forward(self, x,label):
    # need to let the shape of the label become (batch_size,1,32,32), now it's (batch_size,12)
    label = self.process_label(label)
    label = torch.reshape(label,(-1,1,32,32))

    # print("label shape after reshape: ",label.shape)
    x = torch.cat([x,label],1)
    out = self.conv(x)
    out = out.view(-1, 256 * 32 * 32)
    out = self.fc(out)
    return out

  # weight_init
  def weight_init(self, mean, std):
    for m in self._modules:
        normal_init(self._modules[m], mean, std)

def label_preprocess(label):
    # change the label from dataloader in (batch_size,) to (batch_size,num_class)
    label = label.type(torch.LongTensor)
    return MAP[label]

device

random_z = torch.randn(1,100).to(device)
#label_input = label_preprocess(label_input)
label_dict = {'Red':0, 'Yellow':1, 'Green':2, 'Black':3}
#test_label = torch.tensor([label_dict[label_input]])
test_label = torch.tensor([int('0')]).to(device)
fixed_y = label_preprocess(test_label).to(device) 
model = generator()	# 导入网络结构
model.load_state_dict(torch.load('/content/drive/MyDrive/GAN/datasets/cDCGAN_generator_param.pkl')) # 导入网络的参数#
test_images = model(random_z, fixed_y)

from google.colab import drive
drive.mount('/content/drive')

def give_result(label_input):
    # random_z = torch.randn(1,100).to(device)
    random_z = (torch.randint(0, 255, (1,100))/255).to(device)
    label_dict = {'Red':0, 'Yellow':1, 'Green':2, 'Black':3}
    test_label = torch.tensor([label_dict[label_input]])
    #test_label = torch.tensor([int(label_input)])
    fixed_y = label_preprocess(test_label).to(device) 
    model = generator()	
    model.load_state_dict(torch.load('cDCGAN_generator_param.pkl'))
    test_images = model(random_z, fixed_y)
    print(test_images)
    # print(test_images.shape)
    image = Image.fromarray(test_images[0,0].cpu().data.numpy())
    if image.mode == "F":
       image = image.convert('RGB')
    return image

!pip install gradio

import gradio as gr

demo = gr.Interface(
    fn=give_result,
    inputs=gr.Textbox(lines=1, placeholder="Name Here..."),
    outputs='image'
)
demo.launch()